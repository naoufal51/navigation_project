{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_id 1989\n",
      "Mono path[0] = '/Users/Naoufal_1/Desktop/repos/navigation_project/p1_navigation/Banana.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/Naoufal_1/Desktop/repos/navigation_project/p1_navigation/Banana.app/Contents/MonoBleedingEdge/etc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 18.0\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from agent import DQNAgent, DoubleDQNAgent\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def load_agent(agent: DQNAgent, file_name: str = \"checkpoint.pth\") -> int:\n",
    "    \"\"\"\n",
    "    Load agent's Q-network weights and optionally episode number from a file.\n",
    "\n",
    "    Args:\n",
    "        agent (DQNAgent): The agent to which the Q-network weights should be loaded.\n",
    "        file_name (str): The path to the file from which the data should be loaded.\n",
    "\n",
    "    Returns:\n",
    "        int or None: The episode number at which the model was saved or None if not saved.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(file_name)\n",
    "    agent.q_network.load_state_dict(checkpoint[\"q_network_state_dict\"])\n",
    "    agent.q_network.eval()  # Set the network to evaluation mode\n",
    "    return checkpoint.get(\"episode\", None)\n",
    "\n",
    "\n",
    "seed=32\n",
    "worker_id=randint(0, 10000)\n",
    "print('worker_id', worker_id)\n",
    "env = UnityEnvironment(file_name=\"Banana.app\", worker_id=worker_id, seed=seed)\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# Create DQN agent\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size = len(env_info.vector_observations[0])\n",
    "agent = DoubleDQNAgent(state_size=state_size, action_size=action_size,fc1_dim=128, fc2_dim=64, seed=seed, dueling=True)\n",
    "\n",
    "# load model to agent\n",
    "load_agent(agent, './models/navigation_dqn_checkpoint_dueling_True_double_True.pth')\n",
    "\n",
    "# put env on eval model\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "# initialize state\n",
    "state = env_info.vector_observations[0]\n",
    "\n",
    "# initialize score\n",
    "total_score = 0\n",
    "\n",
    "while True:\n",
    "    action = agent.act(state)                      # select action \n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    total_score += reward\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(\"Score: {}\".format(total_score))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_id 2035\n",
      "Mono path[0] = '/Users/Naoufal_1/Desktop/repos/navigation_project/p1_navigation/Banana.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/Naoufal_1/Desktop/repos/navigation_project/p1_navigation/Banana.app/Contents/MonoBleedingEdge/etc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfc0lEQVR4nO3debhcVZnv8e+PJCQBAoiJEENClDGAMkWQlqsgzhcavW2DODCYFqMQZFKQaBNbkjYtg4poBMPgQHAAGqdWEFGJChogyhAQkDA1Q8JMhBDDe/9Yq8JOUeecOie1T1Vl/z7Pc55Ttcd3rb3qrVWrVlUpIjAzs+pYp90BmJnZ4HLiNzOrGCd+M7OKceI3M6sYJ34zs4px4jczqxgn/rWUpFMlLZX0ULtjGQxKzpf0uKQ/lnSOxZLekm+fLOmbhXXvkXSfpGck7SJpW0kLJT0t6egy4qkiSRMlhaShPaxf7bpYY5VL/JJ+nZPD8EE8Z0jaahDPNwE4Htg+IjYbrPO22V7AW4HNI2L3sk8WEbMi4t8Ki04DjoqIDSLiRuBTwNURMSoivlJ2PEWSZkj6Th/bLJb0bH5iekLS7yVNlbROYZsLJD2fn8wek3SlpO0K6w+TNL/MsvRX8br09STRH83UaTepVOKXNBH4P0AA/9zeaMqRG/kE4NGIeGSA+3ejLYDFEbGsvzu2qMxbALf0cn+w42nG/hExihTrF4ATgbl12/xXRGwAjAMeaLC+5bq4Dfao48oUEZX5A/4d+B1wBvCTunUvB34MPAX8CTgVmF9Yvx1wJfAYcDtwYGHdBcDZwE+Bp4HrgC3zut+SnmiWAc8ABzWI67Ac11eBJ4HbgH0L6zciPeAeJD34TgWG1O17JvAoMB94Fnghn++CvN0/kxLRE8CvgUmF4y8mPej/AiwHtsoxHw7cBzwOTAVel7d5AvhqYf8tgV/l8y8FvgtsXHf8E/K+TwLfA0YU1h8ALMx1fxfwjr7KXVd/U4DngJW5zJ/Lyz8C3Jmv2Y+AVxb2CeBI4A7g7h7ay4eAe3K5pudyvCWvmwF8Bxiez1m7xnfluliZY3oG2CZvdxpwL/AwMAcYmY+1N3B/vgYPAd8mdcpOysd7FPg+sEnefmI+36H5eEuB6XndO4DngRX53H/uoWyrylJYtjup3exYaNenFta/C1hW127nNzp+g/PVyvI0cCvwngbtv9aGTwVGAqfn+n+S1K5H9lb24nXJt+/N2z6T//bMyz8MLCK1618AWxT234EXH+cPAyf3VKf1dVh37lqcU3Icv+3t3IBy+R8hPQ5uql2HUnLhYCXdTvgjJYGPA7vli7hpYd3F+W89YHtSwpuf162f7x8ODAV2yQ1u+8ID5NH8wBlKSnwXF44dwFa9xHUY8A/gWGAYcFBu7LUH+mXAN3IcrwD+CHy0bt9p+dwjyYmkcPxtSEnprfn4n8p1sW6hAS8ExrP6g2sOMAJ4GymJ/Xc+/7jcQN+U998qH3s4MIb0ZPelwvkX55hfCWySG/7UvG73XNa3kpLdOGC7vsrdQx0Wn6jfnK/Rrjmus8gPvsI1uTLHM7LB8bYnPcjfmPc/I9fzaom/p2tMenL9t8L9M0lPPpsAo0idjP/M6/bOx56dzzUS+ARwLbB5XvYNYF6snlTOzdvuRHrCntQoth7qazF1iT8vvxf4WKFdn1p4DHybwhNJfZ33cb5/zdd/HVL7XgaM7aUNn53rcBwwBPinXA9Nl72w7dBCHAeQ2v6kfK7PAL/P60aROhnHk9r9KGCPnuq0vg57OPe3ct2N7OPcbweuBzYmPQlMqtVPKbmwrAN32h9pDHgFMDrfvw04Nt8ektdtW9h+VY8/N9Rr6o73DeCUwgPkm4V17wJuK9xvJvH/L6DCsj+Sepyb5oY9srDuYNL4cW3fe+uOtzerJ/7PAt8v3F+H1IPeu9CAP1xYX2u04wrLHqXwagW4BDimh/K8G7ixcH8x8MHC/f8C5hTq8cwGx+i13D3UYTHxzyUNU9Tub5Cv8cTCNXlzL9fk31n9yXt9Uq+v34mf9EBeRn4VmJftSX6lka/X86z+KmgRq7/qG5vjH1q4PpvXtZf3NYqth/ItpnHiv5YXXz1cQHrCf4L0SuBu4LU91Xk/H48LgQMatWFS+3wW2KnBfk2XncaJ/3+AKXXn+jtpuOtgCu227rwvqdP6Ouzh3K9u8txvBv4KvB5YZyB12p+/Ko3xHwpcERFL8/2L8jJIvdShpF59TfH2FsAe+U2wJyQ9AXwAKL5xWpw983dSoumPByK3huweUg9pC1Iv/cHCub9B6gE3irWRV+bjARARL+R9xvVxjIcLt59tcH8DAEmbSrpY0gOSniINgYyuO1ZP9TOeNARQr5ly96a+zM+Qnrz6KnNx/1XrI7138GiT5643hvRK8vpCWX6el9csiYjnCve3AC4rbL+INHy0aWGbNW1zjYwjDXPUnBYRG5MS2bPAtgM5qKRD8iynWnl2ZPU2UrwWo0k97kbtomagZd8C+HIhjsdIT8zj6Lktron6PNLw3BHxK9JQ79nAI5LOkbRhi2NZpRKJX9JI4EDgTZIeylMcjwV2krQTsIT0UnPzwm7jC7fvA34TERsX/jaIiI+1MMxxklS4P4H0KuA+Us93dOHcG0bEDoVti08YjfwvqdEBaeojqXwP9OMYvZmV939NRGwIfJDUoJtxH+k9gkbL+yp3b+rLvD7pfZxmy/wghTYgab28/0AsJSXNHQpl2SjSm6Y9xXIf8M66NjciIh6gbwO6lpJeR0qAL5mpExH3koafvpwfT/057hakoZmjgJfnJ5KbWb2NFGNeSnql0ahd9EejeriPNFxYrNeREfH7vO7V/TjWMtITek2jGXTF/Xo7NxHxlYjYjTTMuA3wyd6LN3CVSPykoYeVpArdOf9NAq4BDomIlcClwAxJ6+Upa4cU9v8JsI2kD0kalv9eJ2lSk+d/mJ4bVM0rgKPzsf81x/eziHgQuAI4XdKGktaRtKWkNzV5bkhvDP5fSftKGkYaw1wO/L4fx+jNKNJ4+JOSxtG/BjsXODzHto6kcZK2a0G55+Xj7pyn7s4CrouIxU3u/0NgP0l7SVoX+A8G+HjJr7DOBc6U9AqAXM6397LbHGBmTppIGiPpgCZP+TAwsTg1sze5fvcjvcf1nYi4qYdyXEl6Qj1i9d01ovjXYNf1SQlwSd7hcFKPv6FcX+cBZ0h6paQhkvYcwBTsJaQhquJjbw7waUk75Fg2yo83SI/zsZKOkTRc0ihJe+R1jep0IfC+/JidDLy3j3h6PHfOJ3vkx+cy0hPfC/0sb9OqkvgPBc6PiHsj4qHaH+ml1QfyVKujSLNIarMq5pGSIxHxNOkNzveRGv5DvPhGXDNmABfml3gH9rDNdcDWpN7OTOC9EVEbWjgEWJc0G+JxUlIa2+S5iYjbSb3ws/Lx9ydN5Xu+2WP04XOkN1GfJM1surQfsf2R9Kb5mXn/3/BiT33A5Y6IX5Le27iE1HvfknT9mo3rFtKsn4vy/o+TZt4M1ImkN/auzcNhv6T3YZMvk94MvkLS06Sx9z162b7oB/n/o5Ju6GW7H+dj30eatXQG6Vr05ovApwpJ+J9Ir2ZW/dVPXYyIW0kzdP5ASqCvIc3i6c0JpJktfyINicymn/kqIv5Oeiz9Lj/2Xh8Rl+VjXZyvw83AO/P2T5MmGexPeozfAeyTD9eoTj9LalePkx4DF/URT4/nBjYkdQ4e58WZZF/sT3n7Q6sPK1uNpNnAZhFxaJ8br/m5DiO9EbhX2ecyM6tKj79PkraT9Folu5Pm317W7rjMzFqtsz5N1l6jSMM7ryS9HD0duLytEZmZlcBDPWZmFeOhHjOziumKoZ7Ro0fHxIkT2x2GmVlXuf7665dGxJj65V2R+CdOnMiCBQvaHYaZWVeRdE+j5R7qMTOrGCd+M7OKceI3M6sYJ34zs4px4jczqxgnfjOzinHiNzOrGCd+M7OK6YoPcJlZz1b/4bY1V+Xv76pKXTrxm3W5ZpKLpI5NQp2k2Trq9vr0UI+ZWcU48ZuZVYwTv5lZxTjxm5lVjBO/mVnFOPGbmVWME7+ZWcV4Hr8Nuqp8SMasUznx26CryodkzDqVh3rMzCrGid/MrGKc+M3MKsaJ38ysYpz4zcwqxonfzKxiPJ2zCZ53bmZrEyf+JnjeuZmtTTzUY2ZWMU78ZmYV48RvZlYxTvxmZhVTWuKXNF7S1ZJulXSLpE/k5ZtIulLSHfn/y8qKwczMXqrMHv8/gOMjYnvg9cCRkrYHTgKuioitgavyfTMzGySlJf6IeDAibsi3nwYWAeOAA4AL82YXAu8uKwYzM3upQRnjlzQR2AW4Dtg0Ih7Mqx4CNu1hnyMkLZC0YMmSJYMRpplZJZSe+CVtAFwCHBMRTxXXRfq0U8NPPEXEORExOSImjxkzpuwwzcwqo9TEL2kYKel/NyIuzYsfljQ2rx8LPFJmDGZmtroyZ/UImAssiogzCqt+BByabx8KXF5WDGZm9lJlflfPG4APATdJWpiXnQx8Afi+pCnAPcCBJcZgZmZ1Skv8ETEf6OlrLfct67xmZtY7f3LXzKxinPjNzCrGid/MrGKc+M3MKsaJ38ysYpz4zcwqxonfzKxinPjNzCrGid/MrGKc+M3MKsaJ38ysYpz4zcwqxonfzKxinPjNzCrGid/MrGKc+M3MKsaJ38ysYpz4zcwqxonfzKxinPjNzCrGid9aauzmE5DUkj+gJccZu/mENtfKwHRiXbo+1476HDroZ7S12kMP3McWJ/6k3WGs5p7Z+7U7hAHpxLoE12ertaM+3eM3M6sYJ34zs4px4jczqxgnfjOzinHiNzOrGCd+M7OKqXzi99xeM6uays/j99xeM6uayvf4zcyqxonfzKxinPjNzCrGid/MrGJKS/ySzpP0iKSbC8tmSHpA0sL8966yzm9mZo2V2eO/AHhHg+VnRsTO+e9nJZ7fzMwaKC3xR8RvgcfKOr6ZmQ1MO+bxHyXpEGABcHxEPN5oI0lHAEcATJjgDzN1izhlQ+D97Q5jdads2O4IrAN0ZNuEtrTPwU78Xwc+D0T+fzrw4UYbRsQ5wDkAkydPjsEK0NaMPvdUx30g7p7Z+xEz2h2FtVsntk1oT/sc1Fk9EfFwRKyMiBeAc4HdB/P8ZmY2yIlf0tjC3fcAN/e0rZmZlaO0oR5J84C9gdGS7gdOAfaWtDNpqGcx8NGyzm9mZo2Vlvgj4uAGi+eWdT4zM2uOP7lrZlYxTvxmZhXjxG9mVjFO/GZmFePEb2ZWMU78ZmYV48RvZlYxlf+xdbNO5S8Vs7I48Zt1KH+pmJXFQz1mZhXTVOKXtKWk4fn23pKOlrRxqZGZmVkpmh3quQSYLGkr0nfkXw5cBHT9b+Z6HNXMqqbZxP9CRPxD0nuAsyLiLEk3lhnYYPE4qplVTbNj/CskHQwcCtSy5LByQjIzszI1m/gPB/YEZkbE3ZJeBXy7vLDMzKwsTQ31RMStkk4EJuT7dwOzywzMzMzK0eysnv2BhcDP8/2dJf2oxLjMzKwkzQ71zCD9MPoTABGxEHh1KRGZmVmpmn5zNyKerFv2QquDMTOz8jU7nfMWSe8HhkjaGjga+H15YZmZWVmaTfzTgOnActIHt34BnFpWUNa9Nhs3nntm79fuMFaz2bjx7Q7BrKP0mfglDQF+GhH7kJK/WY8evP/elh1LEhHRsuOZWdLnGH9ErARekLTRIMRjZmYla3ao5xngJklXAstqCyPi6FKiMjOz0jSb+C/Nf2Zm1uWa/eTuhZLWBbbJi26PiBXlhWVmZmVpKvFL2hu4EFgMCBgv6dCI+G1pkZmZWSmaHeo5HXhbRNwOIGkbYB6wW1mBmZlZOZpN/MNqSR8gIv4qyV/LbGZdoxM/YwLt+ZxJs4l/gaRvAt/J9z8ALCgnJDOz1vNnTF7UbOL/GHAk6asaAK4BvlZKRGZmVqpmE/9Q4MsRcQas+jTv8NKiMjOz0jT77ZxXASML90cCv2x9OGZmVrZmE/+IiHimdiffXq+ckMzMrEzNJv5lknat3ZE0GXi2tx0knSfpEUk3F5ZtIulKSXfk/y8bWNhmZjZQzSb+Y4AfSLpG0jXAxcBRfexzAfCOumUnAVdFxNak4aOTmg/VzMxaodfEL+l1kjaLiD8B2wHfA1aQfnv37t72zZ/qfaxu8QGkTwCT/797ADGbmdka6KvH/w3g+Xx7T+Bk4GzgceCcAZxv04h4MN9+CNi0pw0lHSFpgaQFS5YsGcCpzMyskb4S/5CIqPXaDwLOiYhLIuKzwFZrcuJIn37o8RMQEXFOREyOiMljxoxZk1OZmVlBn4lfUm2u/77Arwrrmv0MQNHDksYC5P+PDOAYZma2BvpK/POA30i6nDSL5xoASVsBTw7gfD8CDs23DwUuH8AxzMxsDfTaa4+ImZKuAsYCV8SLX06xDukH2HskaR6wNzBa0v3AKcAXgO9LmgLcAxy4ZuGbmVl/9TlcExHXNlj21yb2O7iHVfs2EZeZmZWk2Xn8Zma2lnDiNzOrGCd+M7OKceI3M6sYJ34zs4px4jczqxgnfjOzinHiNzOrGCd+M7OKceI3M6sYJ34zs4px4jczqxgnfjOzinHiNzOrGCd+M7OKceI3M6sYJ34zs4px4jczqxgnfjOzinHiNzOrmD5/bH1tt9m48dwze792h/ESm40b3+4QrM3cNq0slU/8D95/b8uOJYmIaNnxrNrcNq0sHuoxM6sYJ34zs4px4jczqxgnfjOzinHiNzOrGCd+M7OKqfx0Tht8klq6racpmvWPE78NOidqs/byUI+ZWcU48ZuZVYwTv5lZxTjxm5lVTFve3JW0GHgaWAn8IyImtyMOM7Mqauesnn0iYmkbz29mVkke6jEzq5h2Jf4ArpB0vaQjGm0g6QhJCyQtWLJkySCHZ2a29mpX4t8rInYF3gkcKemN9RtExDkRMTkiJo8ZM2bwIzQzW0u1JfFHxAP5/yPAZcDu7YjDzKyKBj3xS1pf0qjabeBtwM2DHYeZWVW1Y1bPpsBl+cu3hgIXRcTP2xCHmVklDXrij4i/ATsN9nnNzCzxdE7rOPPmzWPHHXdkyJAh7LjjjsybN6/dIZmtVfy1zNZR5s2bx/Tp05k7dy577bUX8+fPZ8qUKQAcfPDBbY7ObO3gHr91lJkzZzJ37lz22Wcfhg0bxj777MPcuXOZOXNmu0MzW2uoG34UY/LkybFgwYJ2h9EnSf6RkTU0ZMgQnnvuOYYNG7Zq2YoVKxgxYgQrV65sY2TdzW2ztbqlPiVd3+i70Nzjt44yadIk5s+fv9qy+fPnM2nSpDZFZLb2ceK3jjJ9+nSmTJnC1VdfzYoVK7j66quZMmUK06dPb3doZmsNv7lrHaX2Bu60adNYtGgRkyZNYubMmX5j16yFPMbfQt0y7mfV47bZWt1Snx7jNzMzwInfzKxynPjNzCrGid/MrGKc+M3MKsaJ38ysYpz4zcwqxonfzKxinPjNzCrGid86jn+Ixaxc/q4e6yj+IRaz8rnHbx3FP8RiVj5/SVsLdcsXN3Uy/xBLOdw2myOppcdrd537S9qsK/iHWKydIqKlf53Kid86in+Ixax8fnPXOop/iMWsfB7jbyGPo1qnctusJo/xW9fwPH6zcnmoxzqK5/Gblc89fusonsdvVj6P8beQx1HXnOfxl8Nts5o8xm9dwfP4zcrnxG8dxfP4zcrnN3eto3gev1n5PMbfQh5HtU7ltllNHuM3MzOgTYlf0jsk3S7pTkkntSMGM7P+mjZtGiNGjEASI0aMYNq0ae0OaUAGPfFLGgKcDbwT2B44WNL2gx2HmVl/TJs2jTlz5jBr1iyWLVvGrFmzmDNnTlcm/3b0+HcH7oyIv0XE88DFwAFtiMPMrGnnnnsus2fP5rjjjmO99dbjuOOOY/bs2Zx77rntDq3f2pH4xwH3Fe7fn5etRtIRkhZIWrBkyZJBC64RSU39NbutWSu1sm26ffZs+fLlTJ06dbVlU6dOZfny5W2KaOA69s3diDgnIiZHxOQxY8a0O5ZK/DiDdSe3z8ExfPhw5syZs9qyOXPmMHz48DZFNHDtmMf/ADC+cH/zvMzMrGN95CMf4cQTTwRST3/OnDmceOKJL3kV0A3akfj/BGwt6VWkhP8+4P1tiMPMrGlnnXUWACeffDLHH388w4cPZ+rUqauWd5O2fIBL0ruALwFDgPMiotevXuyWD3CZmXWSnj7A1ZavbIiInwE/a8e5zcyqrmPf3DUzs3I48ZuZVYwTv5lZxTjxm5lVTFd8LbOkJcA97Y6jCaOBpe0OYi3i+mwd12VrdUt9bhERL/kEbFck/m4haUGjqVM2MK7P1nFdtla316eHeszMKsaJ38ysYpz4W+ucdgewlnF9to7rsrW6uj49xm9mVjHu8ZuZVYwTv5lZxbQ98UtaKWmhpFsk/VnS8ZIGHJekX0uanG//TNLGLYhxoqRnJd0oaZGkP0o6bA2Pd3MP61bF3+SxLpB0d667v0r6lqTNC+s3ysvulHSXpO9KelkhjpA0rbD9V+vLVsI1eqaXsry3H8eZIemBHNsdki4t/n6zpHUlfSmX/U5JP5E0obA+JJ1euH+CpBkDLFYz8a4VbV3SuyX9RdJtkm4uXrN8DR+QNDzfHy1p8ZrGNRj6uj6S9sr1cZuk2yV9vLBuhqS/S3pFYVnDdt4J2p74gWcjYueI2AF4K+lH2E9pxYEj4l0R8UQrjgXcFRG7RMQk0m8IHCPp8BYde019MiJ2ArYFbgR+JWndvG4u8LeI2CoitgTuBC4o7PsI8InC9o2Udo1a4Mwc29bA90hlr31gZRYwCtg2IrYCLgEuLzyYlwP/T9LoQYq169u6pJ2A04ADImI7YH9gtqTdCvuvBD7colgGU4/XR9JmwEXA1FzuNwBTJL2nsP9S4PhBjnlAOiHxrxIRjwBHAEcpOUzSV2vrc49t73z7bZL+IOkGST+QtEH98SQtzj2Oibn3cm5+Nr9C0si8zety72WhpC/21BOvi/NvwHHA0fkYm0j673ycayW9Ni+fIemEQjw3S5qY7w7Nve9Fkn4oab0G8fdZxrq4IiLOBB4C3ilpK2A34POFzf4D2EnStvn+EuAq4NC+yp3PUX+NRkg6X9JNuZe4T469x2uX75+Zr8VVhURdLPtukn4j6XpJv5A0tonYvgdcAbw/1+fhwLERsTKvPx94BnhL3uUfpNkZxzZT9lbq1rYOnADMioi78/q7SU+wxYT3JeBYSW352vdWqL8+wJHABRFxQ16/FPgU8MnCbucBB0naZLDj7a+OSvywqqENAV7R0za5h/YZ4C0RsSuwgNQ4e7M1cHZ+Nn8C+Je8/HzgoxGxM6mn0qwbgO3y7c8BN0bEa4GTgW81sf+2wNdyr+op4OPFlQMsY31s2wMLa4kPIN++EZhU2H42cIKkIc0cvO4aHZkWxWuAg4ELJY3o4xDrAwvytfgNdb1eScOAs4D3RsRupAdUrz/WU1Ar+1bAvRHxVN36BaR6qTkb+ICkjZo8fst0aVvfAbi+bn19nd4LzAc+1I9zdJy669NMuZ8htdVPDEqAa6Bbn5FfT6rw36UnY9YF/tDHPndHxMJ8+3pgotKY6KiIqO17EbBfkzGocHsv8oMrIn4l6eWSNuxj//si4nf59ndIParTCusHUsZGsfUpIv4m6ToG9hOYe5GSNBFxm6R7gG362OcF0rAMpLJfWrd+W2BH4Mpc9iHAg03G09+yPyXpW6T6f7Y/+w6STmvrzfpP4HLgpwPYt5t9BVgo6bQ+t2yjjkv8kl5N6o08QnopXnxVUutJCrgyIg7ux6GXF26vBEauSZzALsCiPrbpKX6A+g9Q1N8fSBmLsV0F3ArsLGmdiHgBQGl8eydSL64Y2yzgh6QeeK/qrlFPeit7vUZlvyUi9uwrlgZ2IfXE7gImSBoVEU8X1u9GGusv+hKpPs4fwPkGrEvb+q2kOvxzYf1upDpfJSLukLQQOHANz902ddenVu7LC5s0KvcTki4ivRLuWB011JPHeucAX430ybLF5MQlaTywe970WuANeQwbSetL6quX+RL5zbCnJe2RF72vyTgnknrntV9Zvgb4QF63N7A0DzEsBnbNy3cFXlU4zARJtcT2ftJL46J+lzGPFR8NjAV+HhF3koZ1PlPY7DPAVRFxb3HfiLiN1Lj37+Mc9deoWPZtgAnA7fR87SC1u9pMkEZlvx0YU6sfScMk7dBbXHm7fwHeBsyLiGXAhcAZtSEsSYcAzwG/K+4XEY8B3wem9HWOVunitn4a8Om8vLb+GOCLDXafSXpPoOs0uD5nA4dJ2jmvfzmpfJ9vsPsZwEfpwI51TScENjL3DIaRej3fJlUcpAfo3aSEtIjUKyMilihNMZunPG2MlND+OoDzTwHOlfQCqbf7ZA/bbSnpRlJP7GngKxFxQV43AzhP0l+Av/PiG6WXAIdIugW4ri6+24EjJZ2Xy/f14sn6WcYvSvossB4pUewTEc/ndR8GzpJ0F7Ah8Cd6Tu4zSU8U9Xq7Rl8Dvi7pprzusIhYLqnhtcuWAbtL+gypN3VQXdmfV5oi+JU89j6U1Cu/pUFsx0r6IOl9g5uBN0fEkrzu06SEdHt+g3MJsGc0/rj66cBRDWuldbq+rUfEQkknAj/O8Uwktbfb6w8SEbdIuoHc+ekCPV6fiHgwt7NzcpucSGrrL3mFHBFLJV1GGyYNNKvyX9kgaYOIeCbfPgkYGxEd/+bMQCjN5PkpcHSkH7yvDKXpeP8DfD0iuvp7VgaqjLYu6QvAHsDbC52NtZ7SHP6PAW+MiMfbHU9/OfFLB5F6hkNJP/ZyWKHHaLbWcFu3msonfjOzqumoN3fNzKx8TvxmZhXjxG9mVjFO/GZmFePEb2ZWMf8f+0TbmQJjOBsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import deque\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from agent import DQNAgent, DoubleDQNAgent\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def load_agent(agent: DQNAgent, file_name: str = \"checkpoint.pth\") -> int:\n",
    "    \"\"\"\n",
    "    Load agent's Q-network weights and optionally episode number from a file.\n",
    "\n",
    "    Args:\n",
    "        agent (DQNAgent): The agent to which the Q-network weights should be loaded.\n",
    "        file_name (str): The path to the file from which the data should be loaded.\n",
    "\n",
    "    Returns:\n",
    "        int or None: The episode number at which the model was saved or None if not saved.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(file_name)\n",
    "    agent.q_network.load_state_dict(checkpoint[\"q_network_state_dict\"])\n",
    "    agent.q_network.eval()  # Set the network to evaluation mode\n",
    "    return checkpoint.get(\"episode\", None)\n",
    "\n",
    "\n",
    "# Initialize the environment\n",
    "seed=32\n",
    "worker_id=randint(0, 10000)\n",
    "print('worker_id', worker_id)\n",
    "env = UnityEnvironment(file_name=\"Banana.app\", worker_id=worker_id, seed=seed)\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# Create DQN agent\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size = len(env_info.vector_observations[0])\n",
    "\n",
    "def evaluate_agent(agent_type, dueling: bool, model_path: str, num_episodes: int = 100) -> List[float]:\n",
    "    \"\"\"Evaluates our Banana collection agents over multiple episodes and returns scores.\n",
    "    \n",
    "    Args:\n",
    "        agent_type (DQNAgent or DoubleDQNAgent): The type of agent to be evaluated (Here the difference is in the Double component)\n",
    "        dueling (bool): Whether to use the dueling architecture or not.\n",
    "        model_path (str): The model path where the trained model is saved and should be loaded from.\n",
    "        num_episodes (int): The number of evaluation episodes.\n",
    "        \n",
    "    Returns:\n",
    "        scores (List[float]): The list of scores obtained in the evaluation.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Instantiate agent\n",
    "    agent = agent_type(state_size=state_size, action_size=action_size, fc1_dim=128, fc2_dim=64, seed=seed, dueling=dueling)\n",
    "    \n",
    "    # Load agent from the provided model path\n",
    "    load_agent(agent, model_path)\n",
    "    \n",
    "    scores = []\n",
    "    for i_episode in range(1, num_episodes + 1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0]\n",
    "        total_score = 0\n",
    "        while True:\n",
    "            action = agent.act(state)  # select action \n",
    "            env_info = env.step(action)[brain_name] # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0] # get the next state\n",
    "            reward = env_info.rewards[0] # get the generated reward\n",
    "            done = env_info.local_done[0] # check if the episode is finished\n",
    "            total_score += reward # accumulate the episode reward score\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "        scores.append(total_score)\n",
    "    return scores\n",
    "\n",
    "# Agent configurations to be evaluated\n",
    "configurations = [\n",
    "    (DoubleDQNAgent, True, './models/navigation_dqn_dueling_True_double_True.pth'),\n",
    "    (DoubleDQNAgent, False, './models/navigation_dqn_dueling_False_double_True.pth'),\n",
    "    (DQNAgent, True, './models/navigation_dqn_dueling_True_double_False.pth'),\n",
    "    (DQNAgent, False, './models/navigation_dqn_dueling_False_double_False.pth')\n",
    "]\n",
    "\n",
    "labels = [\"Dueling Double DQN\", \"Double DQN\", \"Dueling DQN\", \"DQN\"]\n",
    "all_scores = [evaluate_agent(agent_type=conf[0], dueling=conf[1], model_path=conf[2]) for conf in configurations]\n",
    "\n",
    "# Plot boxplots\n",
    "plt.boxplot(all_scores, vert=True, patch_artist=True, labels=labels)\n",
    "plt.title('Agent performance for different DRL architectures')\n",
    "plt.ylabel('Scores')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "scores = {'labels':labels,\n",
    "          'all_scores': all_scores}\n",
    "\n",
    "# save scores to file\n",
    "save_dir = './models/'\n",
    "with open(os.path.join(save_dir, 'scores.pkl'), 'wb') as f:\n",
    "    pickle.dump(scores, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dueling Double DQN  Double DQN  Dueling DQN         DQN\n",
      "count          100.000000  100.000000   100.000000  100.000000\n",
      "mean            11.590000   13.990000    12.160000   13.350000\n",
      "std              5.606805    4.118191     6.548529    4.985585\n",
      "min              0.000000    1.000000     0.000000    0.000000\n",
      "25%              7.000000   12.000000     7.000000   11.000000\n",
      "50%             13.000000   15.000000    13.500000   15.000000\n",
      "75%             16.000000   17.000000    17.000000   17.000000\n",
      "max             21.000000   22.000000    23.000000   23.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read scores.pkl \n",
    "scores = pd.read_pickle('./models/scores.pkl')\n",
    "\n",
    "df_scores = pd.DataFrame(scores['all_scores']).transpose()\n",
    "df_scores.columns = scores['labels']\n",
    "\n",
    "# Display the summary statistics for each configuration\n",
    "statistics = df_scores.describe()\n",
    "\n",
    "print(statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
